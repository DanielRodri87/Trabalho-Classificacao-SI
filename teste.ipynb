{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70845aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, cohen_kappa_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ==================== CONFIGURAÇÕES ====================\n",
    "ARQUIVO_TRAIN = 'cvd/train.csv'\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e771d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas(y_true, y_pred):\n",
    "    \"\"\"Calcula todas as métricas de avaliação\"\"\"\n",
    "    return {\n",
    "        'Acurácia': accuracy_score(y_true, y_pred),\n",
    "        'Precisão': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'F1-Score': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'Kappa': cohen_kappa_score(y_true, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c14ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imprimir_resultados(nome_metodo, metricas_lista):\n",
    "    \"\"\"Imprime resultados formatados com média e desvio padrão\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RESULTADOS: {nome_metodo}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Converter lista de dicionários em DataFrame para facilitar cálculos\n",
    "    df_metricas = pd.DataFrame(metricas_lista)\n",
    "    \n",
    "    print(f\"\\n{'Métrica':<15} {'Média':<12} {'Desvio Padrão':<15}\")\n",
    "    print(f\"{'-'*42}\")\n",
    "    \n",
    "    for metrica in df_metricas.columns:\n",
    "        media = df_metricas[metrica].mean()\n",
    "        std = df_metricas[metrica].std()\n",
    "        print(f\"{metrica:<15} {media:.4f}       {std:.4f}\")\n",
    "    \n",
    "    print(f\"\\nNúmero de execuções: {len(metricas_lista)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cde4b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_melhor_k(X_train, y_train, X_val, y_val, k_range=range(1, 31)):\n",
    "    \"\"\"Encontra o melhor valor de K usando conjunto de validação\"\"\"\n",
    "    melhores_scores = []\n",
    "    \n",
    "    for k in k_range:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_val)\n",
    "        score = f1_score(y_val, y_pred, zero_division=0)\n",
    "        melhores_scores.append((k, score))\n",
    "    \n",
    "    melhor_k = max(melhores_scores, key=lambda x: x[1])[0]\n",
    "    return melhor_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12faae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessar_dados(df):\n",
    "    \"\"\"Preprocessa o dataset: trata datas, valores ausentes e codifica variáveis\"\"\"\n",
    "    df_proc = df.copy()\n",
    "    \n",
    "    # Remover colunas não necessárias\n",
    "    colunas_remover = ['id', 'location', 'sym_on', 'hosp_vis']\n",
    "    df_proc = df_proc.drop(columns=[col for col in colunas_remover if col in df_proc.columns])\n",
    "    \n",
    "    # Codificar variáveis categóricas\n",
    "    le_country = LabelEncoder()\n",
    "    le_gender = LabelEncoder()\n",
    "    \n",
    "    if 'country' in df_proc.columns:\n",
    "        df_proc['country'] = le_country.fit_transform(df_proc['country'].astype(str))\n",
    "    \n",
    "    if 'gender' in df_proc.columns:\n",
    "        df_proc['gender'] = le_gender.fit_transform(df_proc['gender'].astype(str))\n",
    "    \n",
    "    # Codificar colunas de sintomas (symptom1, symptom2, etc.)\n",
    "    symptom_cols = [col for col in df_proc.columns if col.startswith('symptom')]\n",
    "    for col in symptom_cols:\n",
    "        if col in df_proc.columns:\n",
    "            # Converter sintomas em variáveis categóricas numéricas\n",
    "            le_symptom = LabelEncoder()\n",
    "            # Substituir NA por string antes de codificar\n",
    "            df_proc[col] = df_proc[col].fillna('no_symptom')\n",
    "            df_proc[col] = le_symptom.fit_transform(df_proc[col].astype(str))\n",
    "    \n",
    "    # Tratar valores ausentes\n",
    "    # Para colunas numéricas, preencher com a mediana\n",
    "    numeric_cols = df_proc.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        df_proc[col] = df_proc[col].fillna(df_proc[col].median())\n",
    "    \n",
    "    # Para colunas categóricas, preencher com a moda e depois codificar\n",
    "    categorical_cols = df_proc.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        df_proc[col] = df_proc[col].fillna(df_proc[col].mode()[0] if len(df_proc[col].mode()) > 0 else 'unknown')\n",
    "        # Codificar se ainda houver colunas categóricas\n",
    "        if df_proc[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            df_proc[col] = le.fit_transform(df_proc[col].astype(str))\n",
    "    \n",
    "    return df_proc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85935007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLASSIFICAÇÃO KNN - COVID-19 DATASET\n",
      "============================================================\n",
      "\n",
      "Carregando dataset de treino...\n",
      "Dataset carregado: 222 amostras, 16 features\n",
      "\n",
      "Distribuição da classe alvo (result - morreu ou não):\n",
      "  Recuperados (0): 159\n",
      "  Falecidos (1): 63\n",
      "\n",
      "Dataset após preprocessamento:\n",
      "  Amostras: 222\n",
      "  Features: 11\n",
      "  Features utilizadas: ['country', 'gender', 'age', 'vis_wuhan', 'from_wuhan', 'symptom1', 'symptom2', 'symptom3', 'symptom4', 'symptom5', 'symptom6']\n",
      "\n",
      "============================================================\n",
      "ETAPA 1: ENCONTRANDO MELHOR VALOR DE K (usando validação)\n",
      "============================================================\n",
      "\n",
      "Tamanho dos conjuntos:\n",
      "  - Treino: 154 amostras (69.4%)\n",
      "  - Validação: 23 amostras (10.4%)\n",
      "  - Teste: 45 amostras (20.3%)\n",
      "\n",
      ">>> MELHOR VALOR DE K ENCONTRADO: 2\n",
      "\n",
      "\n",
      "============================================================\n",
      "MÉTODO 1: HOLD-OUT (70/30)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "RESULTADOS: Hold-Out (70/30)\n",
      "============================================================\n",
      "\n",
      "Métrica         Média        Desvio Padrão  \n",
      "------------------------------------------\n",
      "Acurácia        0.8866       0.0334\n",
      "Precisão        0.9103       0.0704\n",
      "Recall          0.6702       0.1114\n",
      "F1-Score        0.7657       0.0826\n",
      "Kappa           0.6943       0.0990\n",
      "\n",
      "Número de execuções: 30\n",
      "\n",
      "\n",
      "============================================================\n",
      "MÉTODO 2: K-FOLD CROSS-VALIDATION (K=5)\n",
      "============================================================\n",
      "Fold 1/5 concluído\n",
      "Fold 2/5 concluído\n",
      "Fold 3/5 concluído\n",
      "Fold 4/5 concluído\n",
      "Fold 5/5 concluído\n",
      "\n",
      "============================================================\n",
      "RESULTADOS: K-Fold (K=5)\n",
      "============================================================\n",
      "\n",
      "Métrica         Média        Desvio Padrão  \n",
      "------------------------------------------\n",
      "Acurácia        0.9097       0.0392\n",
      "Precisão        0.9271       0.0774\n",
      "Recall          0.7496       0.0957\n",
      "F1-Score        0.8261       0.0734\n",
      "Kappa           0.7654       0.0973\n",
      "\n",
      "Número de execuções: 5\n",
      "\n",
      "\n",
      "============================================================\n",
      "MÉTODO 3: LEAVE-ONE-OUT CROSS-VALIDATION\n",
      "============================================================\n",
      "Processando 222 iterações...\n",
      "  Progresso: 50/222\n",
      "  Progresso: 100/222\n",
      "  Progresso: 150/222\n",
      "  Progresso: 200/222\n",
      "\n",
      "============================================================\n",
      "RESULTADOS: Leave-One-Out\n",
      "============================================================\n",
      "\n",
      "Métrica         Valor        Desvio Padrão  \n",
      "------------------------------------------\n",
      "Acurácia        0.9054       0.0000\n",
      "Precisão        0.9200       0.0000\n",
      "Recall          0.7302       0.0000\n",
      "F1-Score        0.8142       0.0000\n",
      "Kappa           0.7518       0.0000\n",
      "\n",
      "Número de execuções: 222 (uma por amostra)\n",
      "\n",
      "\n",
      "############################################################\n",
      "RESUMO COMPARATIVO DOS MÉTODOS\n",
      "############################################################\n",
      "\n",
      "Valor de K utilizado: 2\n",
      "Dataset: 222 amostras, 11 features\n",
      "\n",
      "Método           Acurácia(μ±σ)    F1-Score(μ±σ)    Precisão(μ±σ)\n",
      "----------------------------------------------------------------------\n",
      "Hold-Out         0.8866±0.0334   0.7657±0.0826   0.9103±0.0704\n",
      "K-Fold (5)       0.9097±0.0392   0.8261±0.0734   0.9271±0.0774\n",
      "Leave-One-Out    0.9054±0.0000   0.8142±0.0000   0.9200±0.0000\n",
      "\n",
      "Métrica         Hold-Out     K-Fold       LOO         \n",
      "-------------------------------------------------------\n",
      "Recall          0.6702±0.1114   0.7496±0.0957   0.7302±0.0000\n",
      "Kappa           0.6943±0.0990   0.7654±0.0973   0.7518±0.0000\n",
      "\n",
      "############################################################\n",
      "ANÁLISE CONCLUÍDA\n",
      "############################################################\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CLASSIFICAÇÃO KNN - COVID-19 DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nCarregando dataset de treino...\")\n",
    "df = pd.read_csv(ARQUIVO_TRAIN)\n",
    "\n",
    "print(f\"Dataset carregado: {df.shape[0]} amostras, {df.shape[1]} features\")\n",
    "\n",
    "# Criar coluna 'result' baseada em 'death' e 'recov'\n",
    "# result = 1 se morte (death=1), result = 0 se recuperado ou sem informação\n",
    "if 'death' in df.columns:\n",
    "    df['result'] = df['death'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    print(f\"\\nDistribuição da classe alvo (result - morreu ou não):\")\n",
    "    print(f\"  Recuperados (0): {(df['result'] == 0).sum()}\")\n",
    "    print(f\"  Falecidos (1): {(df['result'] == 1).sum()}\")\n",
    "else:\n",
    "    print(\"\\nERRO: Coluna 'death' não encontrada no dataset!\")\n",
    "    exit()\n",
    "\n",
    "# Remover linhas onde não há informação de death\n",
    "if 'death' in df.columns:\n",
    "    df = df[df['death'].notna()].copy()\n",
    "if 'recov' in df.columns:\n",
    "    df = df[df['recov'].notna() | df['death'].notna()].copy()\n",
    "\n",
    "# Remover colunas 'death' e 'recov' das features\n",
    "colunas_remover_target = []\n",
    "if 'death' in df.columns:\n",
    "    colunas_remover_target.append('death')\n",
    "if 'recov' in df.columns:\n",
    "    colunas_remover_target.append('recov')\n",
    "\n",
    "if colunas_remover_target:\n",
    "    df = df.drop(colunas_remover_target, axis=1)\n",
    "\n",
    "# Preprocessar dados\n",
    "df_processado = preprocessar_dados(df)\n",
    "\n",
    "# Separar features e target\n",
    "X = df_processado.drop('result', axis=1)\n",
    "y = df_processado['result']\n",
    "\n",
    "print(f\"\\nDataset após preprocessamento:\")\n",
    "print(f\"  Amostras: {X.shape[0]}\")\n",
    "print(f\"  Features: {X.shape[1]}\")\n",
    "print(f\"  Features utilizadas: {list(X.columns)}\")\n",
    "\n",
    "# Verificar se há dados suficientes\n",
    "if len(X) < 10:\n",
    "    print(\"\\nERRO: Dataset muito pequeno para análise!\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ETAPA 1: ENCONTRANDO MELHOR VALOR DE K (usando validação)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Dividir em treino+validação (80%) e teste (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Dividir treino+validação em treino (70% do total) e validação (10% do total)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.125, random_state=RANDOM_STATE, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"\\nTamanho dos conjuntos:\")\n",
    "print(f\"  - Treino: {len(X_train)} amostras ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  - Validação: {len(X_val)} amostras ({len(X_val)/len(X)*100:.1f}%)\")\n",
    "print(f\"  - Teste: {len(X_test)} amostras ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Normalizar dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Encontrar melhor K\n",
    "melhor_k = encontrar_melhor_k(X_train_scaled, y_train, X_val_scaled, y_val)\n",
    "print(f\"\\n>>> MELHOR VALOR DE K ENCONTRADO: {melhor_k}\")\n",
    "\n",
    "# ==================== MÉTODO 1: HOLD-OUT (70/30) ====================\n",
    "\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"MÉTODO 1: HOLD-OUT (70/30)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Repetir hold-out 30 vezes para calcular desvio padrão\n",
    "metricas_holdout = []\n",
    "\n",
    "for i in range(30):\n",
    "    # Nova divisão a cada iteração\n",
    "    X_train_ho, X_test_ho, y_train_ho, y_test_ho = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=i, stratify=y\n",
    "    )\n",
    "    \n",
    "    scaler_ho = StandardScaler()\n",
    "    X_train_ho_scaled = scaler_ho.fit_transform(X_train_ho)\n",
    "    X_test_ho_scaled = scaler_ho.transform(X_test_ho)\n",
    "    \n",
    "    # Treinar KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=melhor_k)\n",
    "    knn.fit(X_train_ho_scaled, y_train_ho)\n",
    "    y_pred = knn.predict(X_test_ho_scaled)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    metricas = calcular_metricas(y_test_ho, y_pred)\n",
    "    metricas_holdout.append(metricas)\n",
    "\n",
    "imprimir_resultados(\"Hold-Out (70/30)\", metricas_holdout)\n",
    "\n",
    "# ==================== MÉTODO 2: K-FOLD (K=5) ====================\n",
    "\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"MÉTODO 2: K-FOLD CROSS-VALIDATION (K=5)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "metricas_kfold = []\n",
    "\n",
    "# Normalizar todo o dataset\n",
    "scaler_full = StandardScaler()\n",
    "X_scaled_full = scaler_full.fit_transform(X)\n",
    "\n",
    "fold_num = 1\n",
    "for train_idx, test_idx in kfold.split(X_scaled_full, y):\n",
    "    X_train_kf = X_scaled_full[train_idx]\n",
    "    X_test_kf = X_scaled_full[test_idx]\n",
    "    y_train_kf = y.iloc[train_idx]\n",
    "    y_test_kf = y.iloc[test_idx]\n",
    "    \n",
    "    # Treinar KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=melhor_k)\n",
    "    knn.fit(X_train_kf, y_train_kf)\n",
    "    y_pred = knn.predict(X_test_kf)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    metricas = calcular_metricas(y_test_kf, y_pred)\n",
    "    metricas_kfold.append(metricas)\n",
    "    \n",
    "    print(f\"Fold {fold_num}/5 concluído\")\n",
    "    fold_num += 1\n",
    "\n",
    "imprimir_resultados(\"K-Fold (K=5)\", metricas_kfold)\n",
    "\n",
    "# ==================== MÉTODO 3: LEAVE-ONE-OUT ====================\n",
    "\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"MÉTODO 3: LEAVE-ONE-OUT CROSS-VALIDATION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "metricas_loo = []\n",
    "\n",
    "# Para LOO, vamos fazer por batches para calcular métricas\n",
    "y_true_total = []\n",
    "y_pred_total = []\n",
    "\n",
    "print(f\"Processando {len(X)} iterações...\")\n",
    "\n",
    "iteracao = 0\n",
    "for train_idx, test_idx in loo.split(X_scaled_full):\n",
    "    X_train_loo = X_scaled_full[train_idx]\n",
    "    X_test_loo = X_scaled_full[test_idx]\n",
    "    y_train_loo = y.iloc[train_idx]\n",
    "    y_test_loo = y.iloc[test_idx]\n",
    "    \n",
    "    # Treinar KNN\n",
    "    knn = KNeighborsClassifier(n_neighbors=melhor_k)\n",
    "    knn.fit(X_train_loo, y_train_loo)\n",
    "    y_pred = knn.predict(X_test_loo)\n",
    "    \n",
    "    y_true_total.extend(y_test_loo)\n",
    "    y_pred_total.extend(y_pred)\n",
    "    \n",
    "    iteracao += 1\n",
    "    if iteracao % 50 == 0:\n",
    "        print(f\"  Progresso: {iteracao}/{len(X)}\")\n",
    "\n",
    "# Calcular métricas globais do LOO\n",
    "metricas_loo_global = calcular_metricas(y_true_total, y_pred_total)\n",
    "metricas_loo.append(metricas_loo_global)\n",
    "\n",
    "# Para LOO, o desvio padrão é 0 pois é uma única execução completa\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"RESULTADOS: Leave-One-Out\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\n{'Métrica':<15} {'Valor':<12} {'Desvio Padrão':<15}\")\n",
    "print(f\"{'-'*42}\")\n",
    "\n",
    "for metrica, valor in metricas_loo_global.items():\n",
    "    print(f\"{metrica:<15} {valor:.4f}       0.0000\")\n",
    "\n",
    "print(f\"\\nNúmero de execuções: {len(X)} (uma por amostra)\")\n",
    "\n",
    "# ==================== RESUMO FINAL ====================\n",
    "\n",
    "print(f\"\\n\\n{'#'*60}\")\n",
    "print(\"RESUMO COMPARATIVO DOS MÉTODOS\")\n",
    "print(f\"{'#'*60}\")\n",
    "\n",
    "print(f\"\\nValor de K utilizado: {melhor_k}\")\n",
    "print(f\"Dataset: {len(X)} amostras, {X.shape[1]} features\")\n",
    "print(f\"\\nMétodo           Acurácia(μ±σ)    F1-Score(μ±σ)    Precisão(μ±σ)\")\n",
    "print(f\"{'-'*70}\")\n",
    "\n",
    "# Hold-out\n",
    "df_ho = pd.DataFrame(metricas_holdout)\n",
    "print(f\"Hold-Out         {df_ho['Acurácia'].mean():.4f}±{df_ho['Acurácia'].std():.4f}   \"\n",
    "      f\"{df_ho['F1-Score'].mean():.4f}±{df_ho['F1-Score'].std():.4f}   \"\n",
    "      f\"{df_ho['Precisão'].mean():.4f}±{df_ho['Precisão'].std():.4f}\")\n",
    "\n",
    "# K-Fold\n",
    "df_kf = pd.DataFrame(metricas_kfold)\n",
    "print(f\"K-Fold (5)       {df_kf['Acurácia'].mean():.4f}±{df_kf['Acurácia'].std():.4f}   \"\n",
    "      f\"{df_kf['F1-Score'].mean():.4f}±{df_kf['F1-Score'].std():.4f}   \"\n",
    "      f\"{df_kf['Precisão'].mean():.4f}±{df_kf['Precisão'].std():.4f}\")\n",
    "\n",
    "# LOO\n",
    "print(f\"Leave-One-Out    {metricas_loo_global['Acurácia']:.4f}±0.0000   \"\n",
    "      f\"{metricas_loo_global['F1-Score']:.4f}±0.0000   \"\n",
    "      f\"{metricas_loo_global['Precisão']:.4f}±0.0000\")\n",
    "\n",
    "print(f\"\\n{'Métrica':<15} {'Hold-Out':<12} {'K-Fold':<12} {'LOO':<12}\")\n",
    "print(f\"{'-'*55}\")\n",
    "print(f\"{'Recall':<15} {df_ho['Recall'].mean():.4f}±{df_ho['Recall'].std():.4f}   \"\n",
    "      f\"{df_kf['Recall'].mean():.4f}±{df_kf['Recall'].std():.4f}   \"\n",
    "      f\"{metricas_loo_global['Recall']:.4f}±0.0000\")\n",
    "print(f\"{'Kappa':<15} {df_ho['Kappa'].mean():.4f}±{df_ho['Kappa'].std():.4f}   \"\n",
    "      f\"{df_kf['Kappa'].mean():.4f}±{df_kf['Kappa'].std():.4f}   \"\n",
    "      f\"{metricas_loo_global['Kappa']:.4f}±0.0000\")\n",
    "\n",
    "print(f\"\\n{'#'*60}\")\n",
    "print(\"ANÁLISE CONCLUÍDA\")\n",
    "print(f\"{'#'*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
