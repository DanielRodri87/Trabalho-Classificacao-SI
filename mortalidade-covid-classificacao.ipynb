{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc6b40a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, cohen_kappa_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98929fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== CONFIGURAÇÕES ====================\n",
    "ARQUIVO_TRAIN = 'cvd/train.csv'\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77bda8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== FUNÇÕES AUXILIARES ====================\n",
    "\n",
    "def calcular_metricas(y_true, y_pred):\n",
    "    \"\"\"Calcula todas as métricas de avaliação\"\"\"\n",
    "    return {\n",
    "        'Acurácia': accuracy_score(y_true, y_pred),\n",
    "        'Precisão': precision_score(y_true, y_pred, zero_division=0),\n",
    "        'Recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'F1-Score': f1_score(y_true, y_pred, zero_division=0),\n",
    "        'Kappa': cohen_kappa_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def imprimir_resultados(nome_metodo, metricas_lista):\n",
    "    \"\"\"Imprime resultados formatados com média e desvio padrão\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RESULTADOS: {nome_metodo}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Converter lista de dicionários em DataFrame para facilitar cálculos\n",
    "    df_metricas = pd.DataFrame(metricas_lista)\n",
    "    \n",
    "    print(f\"\\n{'Métrica':<15} {'Média':<12} {'Desvio Padrão':<15}\")\n",
    "    print(f\"{'-'*42}\")\n",
    "    \n",
    "    for metrica in df_metricas.columns:\n",
    "        media = df_metricas[metrica].mean()\n",
    "        std = df_metricas[metrica].std()\n",
    "        print(f\"{metrica:<15} {media:.4f}       {std:.4f}\")\n",
    "    \n",
    "    print(f\"\\nNúmero de execuções: {len(metricas_lista)}\")\n",
    "\n",
    "def preprocessar_dados(df):\n",
    "    \"\"\"Preprocessa o dataset: trata datas, valores ausentes e codifica variáveis\"\"\"\n",
    "    df_proc = df.copy()\n",
    "    \n",
    "    # Remover colunas não necessárias\n",
    "    colunas_remover = ['id', 'location', 'sym_on', 'hosp_vis']\n",
    "    df_proc = df_proc.drop(columns=[col for col in colunas_remover if col in df_proc.columns])\n",
    "    \n",
    "    # Codificar variáveis categóricas\n",
    "    le_country = LabelEncoder()\n",
    "    le_gender = LabelEncoder()\n",
    "    \n",
    "    if 'country' in df_proc.columns:\n",
    "        df_proc['country'] = le_country.fit_transform(df_proc['country'].astype(str))\n",
    "    \n",
    "    if 'gender' in df_proc.columns:\n",
    "        df_proc['gender'] = le_gender.fit_transform(df_proc['gender'].astype(str))\n",
    "    \n",
    "    # Codificar colunas de sintomas (symptom1, symptom2, etc.)\n",
    "    symptom_cols = [col for col in df_proc.columns if col.startswith('symptom')]\n",
    "    for col in symptom_cols:\n",
    "        if col in df_proc.columns:\n",
    "            # Converter sintomas em variáveis categóricas numéricas\n",
    "            le_symptom = LabelEncoder()\n",
    "            # Substituir NA por string antes de codificar\n",
    "            df_proc[col] = df_proc[col].fillna('no_symptom')\n",
    "            df_proc[col] = le_symptom.fit_transform(df_proc[col].astype(str))\n",
    "    \n",
    "    # Tratar valores ausentes\n",
    "    # Para colunas numéricas, preencher com a mediana\n",
    "    numeric_cols = df_proc.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        df_proc[col] = df_proc[col].fillna(df_proc[col].median())\n",
    "    \n",
    "    # Para colunas categóricas, preencher com a moda e depois codificar\n",
    "    categorical_cols = df_proc.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols:\n",
    "        df_proc[col] = df_proc[col].fillna(df_proc[col].mode()[0] if len(df_proc[col].mode()) > 0 else 'unknown')\n",
    "        # Codificar se ainda houver colunas categóricas\n",
    "        if df_proc[col].dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            df_proc[col] = le.fit_transform(df_proc[col].astype(str))\n",
    "    \n",
    "    return df_proc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81ffaac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLASSIFICAÇÃO KNN - COVID-19 DATASET\n",
      "============================================================\n",
      "\n",
      "Carregando dataset de treino...\n",
      "Dataset carregado: 222 amostras, 16 features\n",
      "\n",
      "Distribuição da classe alvo (result - morreu ou não):\n",
      "  Recuperados (0): 159\n",
      "  Falecidos (1): 63\n",
      "\n",
      "Dataset após preprocessamento:\n",
      "  Amostras: 222\n",
      "  Features: 11\n",
      "  Features utilizadas: ['country', 'gender', 'age', 'vis_wuhan', 'from_wuhan', 'symptom1', 'symptom2', 'symptom3', 'symptom4', 'symptom5', 'symptom6']\n",
      "\n",
      "============================================================\n",
      "DIVISÃO DOS DADOS: TRAIN/TEST (70/30)\n",
      "============================================================\n",
      "\n",
      "Tamanho dos conjuntos:\n",
      "  - Treino: 155 amostras (69.8%)\n",
      "  - Teste: 67 amostras (30.2%)\n",
      "\n",
      "\n",
      "============================================================\n",
      "MÉTODO 1: HOLD-OUT (70/30)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "RESULTADOS: Hold-Out (70/30)\n",
      "============================================================\n",
      "\n",
      "Métrica         Média        Desvio Padrão  \n",
      "------------------------------------------\n",
      "Acurácia        0.8806       0.0328\n",
      "Precisão        0.8396       0.0666\n",
      "Recall          0.7193       0.1000\n",
      "F1-Score        0.7711       0.0692\n",
      "Kappa           0.6914       0.0894\n",
      "\n",
      "Número de execuções: 30\n",
      "\n",
      "\n",
      "============================================================\n",
      "MÉTODO 2: K-FOLD CROSS-VALIDATION (K=5)\n",
      "============================================================\n",
      "Fold 1/5 concluído\n",
      "Fold 2/5 concluído\n",
      "Fold 3/5 concluído\n",
      "Fold 4/5 concluído\n",
      "Fold 5/5 concluído\n",
      "\n",
      "============================================================\n",
      "RESULTADOS: K-Fold (K=5)\n",
      "============================================================\n",
      "\n",
      "Métrica         Média        Desvio Padrão  \n",
      "------------------------------------------\n",
      "Acurácia        0.9007       0.0520\n",
      "Precisão        0.8738       0.0893\n",
      "Recall          0.7598       0.1741\n",
      "F1-Score        0.8057       0.1150\n",
      "Kappa           0.7391       0.1453\n",
      "\n",
      "Número de execuções: 5\n",
      "\n",
      "\n",
      "============================================================\n",
      "MÉTODO 3: LEAVE-ONE-OUT CROSS-VALIDATION\n",
      "============================================================\n",
      "Processando 222 iterações...\n",
      "  Progresso: 50/222\n",
      "  Progresso: 100/222\n",
      "  Progresso: 150/222\n",
      "  Progresso: 200/222\n",
      "\n",
      "============================================================\n",
      "RESULTADOS: Leave-One-Out\n",
      "============================================================\n",
      "\n",
      "Métrica         Valor        Desvio Padrão  \n",
      "------------------------------------------\n",
      "Acurácia        0.9009       0.0000\n",
      "Precisão        0.8475       0.0000\n",
      "Recall          0.7937       0.0000\n",
      "F1-Score        0.8197       0.0000\n",
      "Kappa           0.7515       0.0000\n",
      "\n",
      "Número de execuções: 222 (uma por amostra)\n",
      "\n",
      "\n",
      "############################################################\n",
      "RESUMO COMPARATIVO DOS MÉTODOS\n",
      "############################################################\n",
      "\n",
      "Valor de K utilizado: 5 (padrão)\n",
      "Dataset: 222 amostras, 11 features\n",
      "\n",
      "Método           Acurácia(μ±σ)    F1-Score(μ±σ)    Precisão(μ±σ)\n",
      "----------------------------------------------------------------------\n",
      "Hold-Out         0.8806±0.0328   0.7711±0.0692   0.8396±0.0666\n",
      "K-Fold (5)       0.9007±0.0520   0.8057±0.1150   0.8738±0.0893\n",
      "Leave-One-Out    0.9009±0.0000   0.8197±0.0000   0.8475±0.0000\n",
      "\n",
      "Métrica         Hold-Out     K-Fold       LOO         \n",
      "-------------------------------------------------------\n",
      "Recall          0.7193±0.1000   0.7598±0.1741   0.7937±0.0000\n",
      "Kappa           0.6914±0.0894   0.7391±0.1453   0.7515±0.0000\n",
      "\n",
      "\n",
      "============================================================\n",
      "MÉTODO 2: K-FOLD CROSS-VALIDATION (K=5)\n",
      "============================================================\n",
      "Fold 1/5 concluído\n",
      "Fold 2/5 concluído\n",
      "Fold 3/5 concluído\n",
      "Fold 4/5 concluído\n",
      "Fold 5/5 concluído\n",
      "\n",
      "============================================================\n",
      "RESULTADOS: K-Fold (K=5)\n",
      "============================================================\n",
      "\n",
      "Métrica         Média        Desvio Padrão  \n",
      "------------------------------------------\n",
      "Acurácia        0.9007       0.0520\n",
      "Precisão        0.8738       0.0893\n",
      "Recall          0.7598       0.1741\n",
      "F1-Score        0.8057       0.1150\n",
      "Kappa           0.7391       0.1453\n",
      "\n",
      "Número de execuções: 5\n",
      "\n",
      "\n",
      "============================================================\n",
      "MÉTODO 3: STRATIFIED K-FOLD CROSS-VALIDATION (K=5)\n",
      "============================================================\n",
      "Estratificação - proporção de classes mantida em cada fold:\n",
      "  Dataset completo: Classe 0 = 159 (71.6%), Classe 1 = 63 (28.4%)\n",
      "\n",
      "Fold 1/5: Treino -> Classe 0 = 127 (71.8%), Classe 1 = 50 (28.2%)\n",
      "Fold 2/5: Treino -> Classe 0 = 127 (71.8%), Classe 1 = 50 (28.2%)\n",
      "Fold 3/5: Treino -> Classe 0 = 128 (71.9%), Classe 1 = 50 (28.1%)\n",
      "Fold 4/5: Treino -> Classe 0 = 127 (71.3%), Classe 1 = 51 (28.7%)\n",
      "Fold 5/5: Treino -> Classe 0 = 127 (71.3%), Classe 1 = 51 (28.7%)\n",
      "\n",
      "============================================================\n",
      "RESULTADOS: Stratified K-Fold (K=5)\n",
      "============================================================\n",
      "\n",
      "Métrica         Média        Desvio Padrão  \n",
      "------------------------------------------\n",
      "Acurácia        0.8877       0.0649\n",
      "Precisão        0.8821       0.1711\n",
      "Recall          0.7449       0.1605\n",
      "F1-Score        0.7892       0.1166\n",
      "Kappa           0.7146       0.1563\n",
      "\n",
      "Número de execuções: 5\n",
      "\n",
      "############################################################\n",
      "ANÁLISE CONCLUÍDA\n",
      "############################################################\n"
     ]
    }
   ],
   "source": [
    "# ==================== CARREGAR E PREPARAR DADOS ====================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CLASSIFICAÇÃO KNN - COVID-19 DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nCarregando dataset de treino...\")\n",
    "df = pd.read_csv(ARQUIVO_TRAIN)\n",
    "\n",
    "print(f\"Dataset carregado: {df.shape[0]} amostras, {df.shape[1]} features\")\n",
    "\n",
    "# Criar coluna 'result' baseada em 'death' e 'recov'\n",
    "# result = 1 se morte (death=1), result = 0 se recuperado ou sem informação\n",
    "if 'death' in df.columns:\n",
    "    df['result'] = df['death'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    print(f\"\\nDistribuição da classe alvo (result - morreu ou não):\")\n",
    "    print(f\"  Recuperados (0): {(df['result'] == 0).sum()}\")\n",
    "    print(f\"  Falecidos (1): {(df['result'] == 1).sum()}\")\n",
    "else:\n",
    "    print(\"\\nERRO: Coluna 'death' não encontrada no dataset!\")\n",
    "    exit()\n",
    "\n",
    "# Remover linhas onde não há informação de death\n",
    "if 'death' in df.columns:\n",
    "    df = df[df['death'].notna()].copy()\n",
    "if 'recov' in df.columns:\n",
    "    df = df[df['recov'].notna() | df['death'].notna()].copy()\n",
    "\n",
    "# Remover colunas 'death' e 'recov' das features\n",
    "colunas_remover_target = []\n",
    "if 'death' in df.columns:\n",
    "    colunas_remover_target.append('death')\n",
    "if 'recov' in df.columns:\n",
    "    colunas_remover_target.append('recov')\n",
    "\n",
    "if colunas_remover_target:\n",
    "    df = df.drop(colunas_remover_target, axis=1)\n",
    "\n",
    "# Preprocessar dados\n",
    "df_processado = preprocessar_dados(df)\n",
    "\n",
    "# Separar features e target\n",
    "X = df_processado.drop('result', axis=1)\n",
    "y = df_processado['result']\n",
    "\n",
    "print(f\"\\nDataset após preprocessamento:\")\n",
    "print(f\"  Amostras: {X.shape[0]}\")\n",
    "print(f\"  Features: {X.shape[1]}\")\n",
    "print(f\"  Features utilizadas: {list(X.columns)}\")\n",
    "\n",
    "# Verificar se há dados suficientes\n",
    "if len(X) < 10:\n",
    "    print(\"\\nERRO: Dataset muito pequeno para análise!\")\n",
    "    exit()\n",
    "\n",
    "# ==================== DIVISÃO TRAIN/TEST (70/30) ====================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"DIVISÃO DOS DADOS: TRAIN/TEST (70/30)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTamanho dos conjuntos:\")\n",
    "print(f\"  - Treino: {len(X_train)} amostras ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"  - Teste: {len(X_test)} amostras ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# Normalizar dados\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ==================== MÉTODO 1: HOLD-OUT (70/30) ====================\n",
    "\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"MÉTODO 1: HOLD-OUT (70/30)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Repetir hold-out 30 vezes para calcular desvio padrão\n",
    "metricas_holdout = []\n",
    "\n",
    "for i in range(30):\n",
    "    # Nova divisão a cada iteração\n",
    "    X_train_ho, X_test_ho, y_train_ho, y_test_ho = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=i, stratify=y\n",
    "    )\n",
    "    \n",
    "    scaler_ho = StandardScaler()\n",
    "    X_train_ho_scaled = scaler_ho.fit_transform(X_train_ho)\n",
    "    X_test_ho_scaled = scaler_ho.transform(X_test_ho)\n",
    "    \n",
    "    # Treinar KNN com valor padrão (k=5)\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train_ho_scaled, y_train_ho)\n",
    "    y_pred = knn.predict(X_test_ho_scaled)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    metricas = calcular_metricas(y_test_ho, y_pred)\n",
    "    metricas_holdout.append(metricas)\n",
    "\n",
    "imprimir_resultados(\"Hold-Out (70/30)\", metricas_holdout)\n",
    "\n",
    "# ==================== MÉTODO 2: K-FOLD (K=5) ====================\n",
    "\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"MÉTODO 2: K-FOLD CROSS-VALIDATION (K=5)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "metricas_kfold = []\n",
    "\n",
    "# Normalizar todo o dataset\n",
    "scaler_full = StandardScaler()\n",
    "X_scaled_full = scaler_full.fit_transform(X)\n",
    "\n",
    "fold_num = 1\n",
    "for train_idx, test_idx in kfold.split(X_scaled_full, y):\n",
    "    X_train_kf = X_scaled_full[train_idx]\n",
    "    X_test_kf = X_scaled_full[test_idx]\n",
    "    y_train_kf = y.iloc[train_idx]\n",
    "    y_test_kf = y.iloc[test_idx]\n",
    "    \n",
    "    # Treinar KNN com valor padrão (k=5)\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train_kf, y_train_kf)\n",
    "    y_pred = knn.predict(X_test_kf)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    metricas = calcular_metricas(y_test_kf, y_pred)\n",
    "    metricas_kfold.append(metricas)\n",
    "    \n",
    "    print(f\"Fold {fold_num}/5 concluído\")\n",
    "    fold_num += 1\n",
    "\n",
    "imprimir_resultados(\"K-Fold (K=5)\", metricas_kfold)\n",
    "\n",
    "# ==================== MÉTODO 3: LEAVE-ONE-OUT ====================\n",
    "\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"MÉTODO 3: LEAVE-ONE-OUT CROSS-VALIDATION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "metricas_loo = []\n",
    "\n",
    "# Para LOO, vamos fazer por batches para calcular métricas\n",
    "y_true_total = []\n",
    "y_pred_total = []\n",
    "\n",
    "print(f\"Processando {len(X)} iterações...\")\n",
    "\n",
    "iteracao = 0\n",
    "for train_idx, test_idx in loo.split(X_scaled_full):\n",
    "    X_train_loo = X_scaled_full[train_idx]\n",
    "    X_test_loo = X_scaled_full[test_idx]\n",
    "    y_train_loo = y.iloc[train_idx]\n",
    "    y_test_loo = y.iloc[test_idx]\n",
    "    \n",
    "    # Treinar KNN com valor padrão (k=5)\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train_loo, y_train_loo)\n",
    "    y_pred = knn.predict(X_test_loo)\n",
    "    \n",
    "    y_true_total.extend(y_test_loo)\n",
    "    y_pred_total.extend(y_pred)\n",
    "    \n",
    "    iteracao += 1\n",
    "    if iteracao % 50 == 0:\n",
    "        print(f\"  Progresso: {iteracao}/{len(X)}\")\n",
    "\n",
    "# Calcular métricas globais do LOO\n",
    "metricas_loo_global = calcular_metricas(y_true_total, y_pred_total)\n",
    "metricas_loo.append(metricas_loo_global)\n",
    "\n",
    "# Para LOO, o desvio padrão é 0 pois é uma única execução completa\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"RESULTADOS: Leave-One-Out\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\n{'Métrica':<15} {'Valor':<12} {'Desvio Padrão':<15}\")\n",
    "print(f\"{'-'*42}\")\n",
    "\n",
    "for metrica, valor in metricas_loo_global.items():\n",
    "    print(f\"{metrica:<15} {valor:.4f}       0.0000\")\n",
    "\n",
    "print(f\"\\nNúmero de execuções: {len(X)} (uma por amostra)\")\n",
    "\n",
    "# ==================== RESUMO FINAL ====================\n",
    "\n",
    "print(f\"\\n\\n{'#'*60}\")\n",
    "print(\"RESUMO COMPARATIVO DOS MÉTODOS\")\n",
    "print(f\"{'#'*60}\")\n",
    "\n",
    "print(f\"\\nValor de K utilizado: 5 (padrão)\")\n",
    "print(f\"Dataset: {len(X)} amostras, {X.shape[1]} features\")\n",
    "print(f\"\\nMétodo           Acurácia(μ±σ)    F1-Score(μ±σ)    Precisão(μ±σ)\")\n",
    "print(f\"{'-'*70}\")\n",
    "\n",
    "# Hold-out\n",
    "df_ho = pd.DataFrame(metricas_holdout)\n",
    "print(f\"Hold-Out         {df_ho['Acurácia'].mean():.4f}±{df_ho['Acurácia'].std():.4f}   \"\n",
    "      f\"{df_ho['F1-Score'].mean():.4f}±{df_ho['F1-Score'].std():.4f}   \"\n",
    "      f\"{df_ho['Precisão'].mean():.4f}±{df_ho['Precisão'].std():.4f}\")\n",
    "\n",
    "# K-Fold\n",
    "df_kf = pd.DataFrame(metricas_kfold)\n",
    "print(f\"K-Fold (5)       {df_kf['Acurácia'].mean():.4f}±{df_kf['Acurácia'].std():.4f}   \"\n",
    "      f\"{df_kf['F1-Score'].mean():.4f}±{df_kf['F1-Score'].std():.4f}   \"\n",
    "      f\"{df_kf['Precisão'].mean():.4f}±{df_kf['Precisão'].std():.4f}\")\n",
    "\n",
    "# LOO\n",
    "print(f\"Leave-One-Out    {metricas_loo_global['Acurácia']:.4f}±0.0000   \"\n",
    "      f\"{metricas_loo_global['F1-Score']:.4f}±0.0000   \"\n",
    "      f\"{metricas_loo_global['Precisão']:.4f}±0.0000\")\n",
    "\n",
    "print(f\"\\n{'Métrica':<15} {'Hold-Out':<12} {'K-Fold':<12} {'LOO':<12}\")\n",
    "print(f\"{'-'*55}\")\n",
    "print(f\"{'Recall':<15} {df_ho['Recall'].mean():.4f}±{df_ho['Recall'].std():.4f}   \"\n",
    "      f\"{df_kf['Recall'].mean():.4f}±{df_kf['Recall'].std():.4f}   \"\n",
    "      f\"{metricas_loo_global['Recall']:.4f}±0.0000\")\n",
    "print(f\"{'Kappa':<15} {df_ho['Kappa'].mean():.4f}±{df_ho['Kappa'].std():.4f}   \"\n",
    "      f\"{df_kf['Kappa'].mean():.4f}±{df_kf['Kappa'].std():.4f}   \"\n",
    "      f\"{metricas_loo_global['Kappa']:.4f}±0.0000\")\n",
    "\n",
    "\n",
    "# ==================== MÉTODO 2: K-FOLD (K=5) ====================\n",
    "\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"MÉTODO 2: K-FOLD CROSS-VALIDATION (K=5)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "metricas_kfold = []\n",
    "\n",
    "# Normalizar todo o dataset\n",
    "scaler_full = StandardScaler()\n",
    "X_scaled_full = scaler_full.fit_transform(X)\n",
    "\n",
    "fold_num = 1\n",
    "for train_idx, test_idx in kfold.split(X_scaled_full, y):\n",
    "    X_train_kf = X_scaled_full[train_idx]\n",
    "    X_test_kf = X_scaled_full[test_idx]\n",
    "    y_train_kf = y.iloc[train_idx]\n",
    "    y_test_kf = y.iloc[test_idx]\n",
    "    \n",
    "    # Treinar KNN com valor padrão (k=5)\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train_kf, y_train_kf)\n",
    "    y_pred = knn.predict(X_test_kf)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    metricas = calcular_metricas(y_test_kf, y_pred)\n",
    "    metricas_kfold.append(metricas)\n",
    "    \n",
    "    print(f\"Fold {fold_num}/5 concluído\")\n",
    "    fold_num += 1\n",
    "\n",
    "imprimir_resultados(\"K-Fold (K=5)\", metricas_kfold)\n",
    "\n",
    "# ==================== MÉTODO 3: STRATIFIED K-FOLD (K=5) ====================\n",
    "\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"MÉTODO 3: STRATIFIED K-FOLD CROSS-VALIDATION (K=5)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "metricas_skfold = []\n",
    "\n",
    "print(\"Estratificação - proporção de classes mantida em cada fold:\")\n",
    "print(f\"  Dataset completo: Classe 0 = {(y==0).sum()} ({(y==0).sum()/len(y)*100:.1f}%), \"\n",
    "      f\"Classe 1 = {(y==1).sum()} ({(y==1).sum()/len(y)*100:.1f}%)\\n\")\n",
    "\n",
    "fold_num = 1\n",
    "for train_idx, test_idx in skfold.split(X_scaled_full, y):\n",
    "    X_train_skf = X_scaled_full[train_idx]\n",
    "    X_test_skf = X_scaled_full[test_idx]\n",
    "    y_train_skf = y.iloc[train_idx]\n",
    "    y_test_skf = y.iloc[test_idx]\n",
    "    \n",
    "    # Mostrar distribuição das classes em cada fold\n",
    "    print(f\"Fold {fold_num}/5: Treino -> Classe 0 = {(y_train_skf==0).sum()} ({(y_train_skf==0).sum()/len(y_train_skf)*100:.1f}%), \"\n",
    "          f\"Classe 1 = {(y_train_skf==1).sum()} ({(y_train_skf==1).sum()/len(y_train_skf)*100:.1f}%)\")\n",
    "    \n",
    "    # Treinar KNN com valor padrão (k=5)\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(X_train_skf, y_train_skf)\n",
    "    y_pred = knn.predict(X_test_skf)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    metricas = calcular_metricas(y_test_skf, y_pred)\n",
    "    metricas_skfold.append(metricas)\n",
    "    \n",
    "    fold_num += 1\n",
    "\n",
    "imprimir_resultados(\"Stratified K-Fold (K=5)\", metricas_skfold)\n",
    "\n",
    "print(f\"\\n{'#'*60}\")\n",
    "print(\"ANÁLISE CONCLUÍDA\")\n",
    "print(f\"{'#'*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
